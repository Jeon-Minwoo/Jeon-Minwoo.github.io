---
layout: post
title: SPG - Unsupervised Domain Adaptaion for 3d Object Detection via Smantic Point Generation
date: 2022-08-12 19:20:23 +0900
category: paper_review
---


### [Domain Gap]

dataset을 촬영한 장소 (Phoenix - PHX, Mountain View - MTV, San Francisco - SF), 촬영한 시간 (Day, Night, Dawn)에 따라 domain shift 발생

Phoenix, Mountain View를 Surburban(SUB)으로 하나의 도메인 취급

SF, SUB 도메인은 비슷한 수의 scenes를 가진다. 

### [Ground truth label]

인지 난이도에 따라 LEVEL_1, LEVEL_2로 나누어 labeling을 한다.<br/><br/>

### [**SPG: Unsupervised Domain Adaptation for 3D Object Detection via Semantic Point Generation (ICCV 2021)]**

---

fig1)

우리의 시맨틱 포인트 생성(SPG)은 시맨틱 포인트(빨간색)를 생성하여 전경 영역을 복구합니다. 의 뜻

원래 클라우드와 결합된 이러한 시맨틱 포인트는 최신 LiDAR 기반 탐지기로 직접 사용할 수 있으며 감지 결과(녹색 상자)를 개선하는 데 도움이 될 수 있습니다.

**[1] Introduction**

domain gap → 포인트 클라우드 퀄리티를 악화시킨다

unsupervised domain adaptation을 통해 3d object detection 성능을 향상

domain gap과 semantic point generation (SPG)를 분석하기 위해 waymo domain adaptation dataset을 사용함

SPG는 target domain과 source domain 둘다 detection 품질을 향상시킬 수 있다 & 현대의 LiDAR 기반 detector와 자연스럽게 합쳐질 수 있다.

1.1 Understanding the Domain Gap

Waymo Open Dataset은 California와 Arizona에서 수집된다. → source domain

Waymo Kirkland Dataset은 Kirkland에서 수집된다. → target domain

OD Training set으로 학습하고  OD, Kirk validation set에서 3d vehicle detection 성능을 비교한다.

rainy weather condition에 의해 target domoain에서 point cloud의 품질이 떨어지는 현상 → “missing point” problem

1.2 Previous Methods to Address the Domain Gap

기존의 방법 - detector의 모델 또는 loss를 redesign 해야만 했다.

본 논문의 목표 - 최근에 쓰이는 LiDAR 기반 detector들 모두 적용할 수 있는 일반적인 solution

(아래는 기존의 방법, 효율이 떨어짐)

source domain을 target domain에 맞추기

target domain을 source domain에 맞추기

style transfer  

1.3 SPG for Closing the Domain Gap

본 논문의 approach는 포인트 클라우드의 semantic 정보를 배우는 것을 목표로 하며 foreground object 안에 있는 복셀을 식별하기 위해 foreground 지역 예측을 수행한다.

예측된 foreground voxels를 기반으로 SPG는 foreground 영역(지역)을 복원할 수 있는 포인트를 만든다. → semantic points

**[3] Semantic Point Generation**

SPG는 raw point cloud를 input으로 취하고, predicted foreground regions에서 semantic points의 sets를 생성한다.

semantic points들은 original point cloud와 합쳐져서 augmented point cloud가 되고, 이 포인트들을 detector에 넣어 결과를 얻는다.

SPG는 PC_raw를 균등한(evenly) 3d voxel grid에 voxel화 한다. 그리고 이러한 voxel들에 대해 point cloud segmentics를 학습한다.

각 voxel에 대해 네트워크는 foreground voxel이 될 확률 confidence를 예측한다. (foreground object bounding box에 포함될 확률)

각 foreground voxel에 대해 네트워크는 **semantic point**를 생성한다. 

관측된 object의 foreground region을 신뢰성 있게 복구하기 위해 **‘generation area’**를 정의한다.

이후 p_thresh보다 낮은 p^~f들은 필터링, p_thresh = 0.5

3.2 Model structure

1) The Voxel Feature Encoding module

여러 MLP를 사용하여 각 복셀 내부의 포인트를 합친다.(집계) [25, 49]와 마찬가지로, 이 복셀 특징은 나중에 기둥에 쌓이고 조감도 기능 공간에 투영된다.

2) The Information Propagation module

pillar feature들에 2d conv를 적용한다. occupied pillars(진한 녹색)의 semantic 정보는 이웃의 empty pillar(밝은 녹색)에 채워져 SPG가 빈 공간의 전경 지역을 복구할 수 있게 해준다.

3) The Point Generation module

해당 복셀에 pillar features를 매핑한다. 

generation area에서의 각각의 voxel v_i는 semantic point sp^~i를 생성한다.

sp^~i ⇒[x^~i, f^~i, P^~i] 각각 point location, point properties, foreground probability

3.3 Foreground region Recovery

1) Hide and Predict

훈련(학습) 중에 소스 도메인에 missing points를 생성하고, SPG가 empty space에서 foreground object shape를 복구하도록 안내한다.

2) Semantic Area Expansion

bbox에서 파생된 foreground background 복셀 레이블을 활용하고 SPG가 각 bbox에서 관찰되지 않은 foreground regions를 더 많이 복구하도록 권장한다?